# üìã DOCUMENTACI√ìN COMPLETA - index.py

## üéØ Prop√≥sito General
Script principal para entrenar un modelo de red neuronal convolucional (CNN) para reconocimiento de lenguaje de se√±as americano (ASL). Implementa un pipeline completo desde la carga de datos hasta la exportaci√≥n del modelo para uso en aplicaciones web.

## üìä Visi√≥n General del Flujo
1. **Configuraci√≥n inicial** ‚Üí Crear carpetas y configurar variables
2. **Carga de datos** ‚Üí Importar y preprocesar im√°genes del dataset ASL
3. **Visualizaci√≥n** ‚Üí Mostrar ejemplos del dataset para verificaci√≥n
4. **Preprocesamiento** ‚Üí Normalizar datos y aplicar aumento de datos
5. **Arquitectura del modelo** ‚Üí Crear CNN optimizada para clasificaci√≥n multiclase
6. **Entrenamiento** ‚Üí Entrenar modelo con datos aumentados
7. **Evaluaci√≥n** ‚Üí Generar m√©tricas y gr√°ficas de rendimiento
8. **Exportaci√≥n** ‚Üí Guardar modelo en formatos Keras y TensorFlow.js

---

## üîç AN√ÅLISIS L√çNEA POR L√çNEA

### **SECCI√ìN 1: IMPORTS Y CONFIGURACI√ìN INICIAL (L√≠neas 1-15)**

```python
# === SISTEMA DE RECONOCIMIENTO DE LENGUAJE DE SE√ëAS AMERICANO (ASL) ===
# Modelo CNN con aumento de datos para clasificar gestos de manos del alfabeto ASL

import os                                    # Manejo de sistema operativo y archivos
import cv2                                   # OpenCV para procesamiento de im√°genes
import numpy as np                           # Operaciones num√©ricas y arrays
import tensorflow as tf                      # Framework de deep learning
import matplotlib.pyplot as plt              # Visualizaci√≥n de gr√°ficas
from tensorflow.keras.callbacks import TensorBoard           # Monitoreo durante entrenamiento
from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Aumento de datos

# Crear carpetas necesarias si no existen
os.makedirs('logs/asl_cnn_augmented', exist_ok=True)        # Carpeta para logs de TensorBoard
os.makedirs('modelo_exportado', exist_ok=True)              # Carpeta para modelo exportado
print("Carpetas de logs y exportaci√≥n creadas")
```

**Detalles t√©cnicos:**
- `os.makedirs(..., exist_ok=True)`: Crea directorios recursivamente sin error si ya existen
- Todas las dependencias son cargadas al inicio para detectar errores temprano
- La estructura de carpetas se configura autom√°ticamente

### **SECCI√ìN 2: CONFIGURACI√ìN DE VARIABLES Y CARGA DE DATOS (L√≠neas 16-33)**

```python
ruta_base = './asl_alphabet_train'          # Directorio ra√≠z del dataset
TAMANO_IMG = 100                           # Dimensi√≥n uniforme para todas las im√°genes

clases = sorted([d for d in os.listdir(ruta_base) 
                if os.path.isdir(os.path.join(ruta_base, d))])
train = []
for idx, clase in enumerate(clases):
    ruta_clase = os.path.join(ruta_base, clase)
    for archivo in os.listdir(ruta_clase):
        if archivo.endswith('.jpg') or archivo.endswith('.png'):
            ruta_img = os.path.join(ruta_clase, archivo)
            img = cv2.imread(ruta_img)
            if img is not None:
                img = cv2.resize(img, (TAMANO_IMG, TAMANO_IMG))    # Redimensionar
                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)        # Convertir a escala de grises
                img = img.reshape(TAMANO_IMG, TAMANO_IMG, 1)       # Agregar dimensi√≥n de canal
                train.append((img, idx))                           # Guardar tupla (imagen, etiqueta)
```

**Detalles t√©cnicos:**
- `sorted()`: Garantiza orden consistente de clases entre ejecuciones
- `enumerate()`: Asigna √≠ndices num√©ricos autom√°ticamente a cada clase
- `cv2.resize()`: Estandariza todas las im√°genes a 100x100 p√≠xeles
- `cv2.cvtColor()`: Convierte de BGR (Blue-Green-Red) a escala de grises para reducir complejidad
- `reshape()`: Agrega dimensi√≥n de canal (100, 100, 1) requerida por TensorFlow
- **Eficiencia de memoria**: Los datos se mantienen como lista de tuplas para evitar duplicaci√≥n

### **SECCI√ìN 3: CREACI√ìN DE ESTRUCTURAS DE DATOS (L√≠neas 34-47)**

```python
# NO crear X ni y como arrays aqu√≠ para evitar duplicaci√≥n de datos y consumo de RAM
datos = {'train': train}
metadatos = {'clases': clases, 'total_imagenes': len(train), 'tamano_img': TAMANO_IMG}

print(f'Total de im√°genes cargadas: {len(train)}')
print(f'Clases encontradas: {clases}')

# Mostrar informaci√≥n b√°sica de los datos y metadatos
print('Metadatos:')
print(metadatos)
print('Primer ejemplo:')
ejemplo_img, ejemplo_et = datos['train'][0]
print(f"Clase: {metadatos['clases'][ejemplo_et]}")
print(f"Tama√±o imagen: {ejemplo_img.shape}")
```

**Detalles t√©cnicos:**
- **Diccionario de datos**: Estructura organizada para acceso eficiente
- **Metadatos**: Informaci√≥n crucial sobre el dataset que se usa en todo el script
- **Validaci√≥n temprana**: Verificar que los datos se cargaron correctamente
- **Shapes esperados**: (100, 100, 1) para cada imagen

### **SECCI√ìN 4: VISUALIZACI√ìN DE DATOS (L√≠neas 48-81)**

```python
# Mostrar 5 ejemplos del set
fig, axs = plt.subplots(1, 5, figsize=(15, 3))
for i in range(5):
    img, etiqueta = datos['train'][i]
    img = img.reshape(metadatos['tamano_img'], metadatos['tamano_img'])  # Remover dimensi√≥n canal para display
    axs[i].imshow(img, cmap='gray')
    axs[i].set_title(metadatos['clases'][etiqueta])
    axs[i].axis('off')
plt.show()

# Mostrar un ejemplo de cada clase
fig, axs = plt.subplots(1, len(metadatos['clases']), figsize=(20, 3))
for idx, clase in enumerate(metadatos['clases']):
    for img, et in datos['train']:
        if et == idx:                                              # Encontrar primera imagen de esta clase
            img = img.reshape(metadatos['tamano_img'], metadatos['tamano_img'])
            axs[idx].imshow(img, cmap='gray')
            axs[idx].set_title(clase)
            axs[idx].axis('off')
            break                                                  # Solo mostrar un ejemplo por clase
plt.tight_layout()
plt.show()

# Visualizaci√≥n extendida de 25 ejemplos
plt.figure(figsize=(20,20))
for i, (imagen, etiqueta) in enumerate(datos['train'][:25]):
    imagen = imagen.reshape(TAMANO_IMG, TAMANO_IMG)
    plt.subplot(5, 5, i+1)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(imagen, cmap='gray')
    plt.title(metadatos['clases'][etiqueta])
plt.show()
```

**Detalles t√©cnicos:**
- **Prop√≥sito**: Verificaci√≥n visual de calidad y variedad del dataset
- `reshape()`: Convierte de (100, 100, 1) a (100, 100) para matplotlib
- `cmap='gray'`: Especifica escala de grises para visualizaci√≥n correcta
- `plt.tight_layout()`: Ajusta autom√°ticamente espaciado entre subplots
- **Grid 5x5**: Muestra distribuci√≥n representativa del dataset

### **SECCI√ìN 5: PREPARACI√ìN DE DATOS PARA ENTRENAMIENTO (L√≠neas 82-95)**

```python
# Preparar arrays X (im√°genes) y y (etiquetas) para entrenamiento
X = np.array([imagen for imagen, etiqueta in datos['train']])
y = np.array([etiqueta for imagen, etiqueta in datos['train']])

# Normalizar datos (0-255 ‚Üí 0-1)
X = X.astype('float32') / 255.0

print(f"Forma de X: {X.shape}")                    # Esperado: (num_images, 100, 100, 1)
print(f"Forma de y: {y.shape}")                    # Esperado: (num_images,)
print(f"N√∫mero de clases: {len(metadatos['clases'])}")
```

**Detalles t√©cnicos:**
- **Conversi√≥n a arrays NumPy**: Requerido por TensorFlow para operaciones eficientes
- **Normalizaci√≥n**: Divisi√≥n por 255.0 convierte valores de p√≠xeles de [0-255] a [0.0-1.0]
- `astype('float32')`: Tipo de dato optimizado para GPUs
- **Verificaci√≥n de shapes**: Validaci√≥n crucial antes del entrenamiento

### **SECCI√ìN 6: CONFIGURACI√ìN DE AUMENTO DE DATOS (L√≠neas 96-133)**

```python
print("\n=== CONFIGURACI√ìN DE AUMENTO DE DATOS ===")

# Configurar generador de aumento de datos
datagen = ImageDataGenerator(
    rotation_range=30,              # Rotaci√≥n aleatoria ¬±30 grados
    width_shift_range=0.2,          # Desplazamiento horizontal ¬±20%
    height_shift_range=0.2,         # Desplazamiento vertical ¬±20%
    shear_range=15,                # Transformaci√≥n de cizalla ¬±15 grados
    zoom_range=[0.7, 1.4],         # Zoom entre 70% y 140%
    horizontal_flip=True,           # Volteo horizontal aleatorio
    vertical_flip=True,             # Volteo vertical aleatorio
    fill_mode='nearest'             # Relleno de p√≠xeles faltantes con valor m√°s cercano
)

datagen.fit(X)                     # Calcular estad√≠sticas necesarias para transformaciones

# Mostrar ejemplos de datos aumentados
plt.figure(figsize=(20, 8))
plt.suptitle('Ejemplos de Aumento de Datos', fontsize=16)

for imagen_aumentada, etiqueta in datagen.flow(X, y, batch_size=10, shuffle=False):
    for i in range(10):
        plt.subplot(2, 5, i+1)
        plt.xticks([])
        plt.yticks([])
        plt.imshow(imagen_aumentada[i].reshape(100, 100), cmap="gray")
        plt.title(f"'{metadatos['clases'][etiqueta[i]]}'")
    break                          # Solo mostrar un lote de ejemplos
plt.tight_layout()
plt.show()
```

**Detalles t√©cnicos:**
- **Data Augmentation**: T√©cnica para aumentar artificialmente el tama√±o del dataset
- **Beneficios**: Mejora generalizaci√≥n, reduce overfitting, aumenta robustez
- `datagen.fit()`: Calcula estad√≠sticas (media, std) necesarias para algunas transformaciones
- `fill_mode='nearest'`: Rellena p√≠xeles vac√≠os despu√©s de transformaciones geom√©tricas

### **SECCI√ìN 7: DIVISI√ìN DE DATOS (L√≠neas 134-144)**

```python
print("\n=== DIVISI√ìN DE DATOS ===")

# Dividir datos en entrenamiento y validaci√≥n (85% - 15%)
split_idx = int(len(X) * 0.85)
X_entrenamiento = X[:split_idx]
X_validacion = X[split_idx:]
y_entrenamiento = y[:split_idx]
y_validacion = y[split_idx:]

print(f"Datos de entrenamiento: {len(X_entrenamiento)} im√°genes")
print(f"Datos de validaci√≥n: {len(X_validacion)} im√°genes")
```

**Detalles t√©cnicos:**
- **Proporci√≥n 85/15**: Divisi√≥n est√°ndar para datasets medianos
- **Validaci√≥n holdout**: Datos nunca vistos durante entrenamiento
- **Slicing secuencial**: Mantiene distribuci√≥n original de clases (si est√° balanceado)
- **Sin shuffle**: Preserva orden para reproducibilidad

### **SECCI√ìN 8: ARQUITECTURA DEL MODELO (L√≠neas 145-172)**

```python
print("\n=== CREACI√ìN DEL MODELO CNN CON AUMENTO DE DATOS ===")

num_clases = len(metadatos['clases'])

# Crear modelo CNN optimizado para ASL con aumento de datos
modelo_asl = tf.keras.models.Sequential([
    # Primera capa convolucional - Detecci√≥n de caracter√≠sticas b√°sicas
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 1)),
    tf.keras.layers.MaxPooling2D(2, 2),          # Reducci√≥n de dimensionalidad 50x50
    
    # Segunda capa convolucional - Caracter√≠sticas m√°s complejas
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),          # Reducci√≥n a 25x25
    
    # Tercera capa convolucional - Caracter√≠sticas de alto nivel
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),          # Reducci√≥n a 12x12
    
    # Regularizaci√≥n y capas densas
    tf.keras.layers.Dropout(0.5),               # 50% de neuronas ignoradas aleatoriamente
    tf.keras.layers.Flatten(),                  # Convertir a vector 1D
    tf.keras.layers.Dense(128, activation='relu'),  # Capa completamente conectada
    tf.keras.layers.Dropout(0.3),               # 30% de dropout adicional
    tf.keras.layers.Dense(num_clases, activation='softmax')  # Clasificaci√≥n multiclase
])
```

**Detalles t√©cnicos:**
- **Arquitectura progresiva**: Filtros aumentan de 32‚Üí64‚Üí128 para capturar complejidad creciente
- **Kernels 3x3**: Tama√±o √≥ptimo para equilibrar receptive field y eficiencia computacional
- **MaxPooling**: Reduce dimensionalidad manteniendo caracter√≠sticas importantes
- **ReLU**: Funci√≥n de activaci√≥n que previene vanishing gradient
- **Dropout**: Regularizaci√≥n para prevenir overfitting
- **Softmax**: Convierte logits en probabilidades que suman 1.0

### **SECCI√ìN 9: COMPILACI√ìN DEL MODELO (L√≠neas 173-185)**

```python
# Compilar modelo
modelo_asl.compile(
    optimizer='adam',                           # Optimizador adaptativo
    loss='sparse_categorical_crossentropy',     # Funci√≥n de p√©rdida para multiclase
    metrics=['accuracy']                        # M√©trica de evaluaci√≥n
)

print("Arquitectura del modelo:")
modelo_asl.summary()                           # Mostrar detalles de la arquitectura
```

**Detalles t√©cnicos:**
- **Adam**: Optimizador que combina momentum y adaptive learning rate
- **Sparse categorical crossentropy**: Para etiquetas enteras (0, 1, 2...) en lugar de one-hot
- **Accuracy**: M√©trica intuitiva para problemas de clasificaci√≥n
- `summary()`: Muestra par√°metros totales y forma de cada capa

### **SECCI√ìN 10: CONFIGURACI√ìN DE ENTRENAMIENTO (L√≠neas 186-202)**

```python
print("\n=== CONFIGURACI√ìN DE ENTRENAMIENTO ===")

# Configurar TensorBoard para monitoreo
tensorboard_callback = TensorBoard(
    log_dir='logs/asl_cnn_augmented',           # Directorio para logs
    histogram_freq=1,                          # Frecuencia de histogramas de pesos
    write_graph=True,                          # Guardar gr√°fico del modelo
    write_images=True                          # Guardar im√°genes de ejemplo
)

# Crear generador de datos de entrenamiento con aumento
data_gen_entrenamiento = datagen.flow(
    X_entrenamiento, 
    y_entrenamiento, 
    batch_size=32                              # Lotes de 32 im√°genes
)

# Configuraci√≥n de entrenamiento
epochs = 100                                   # N√∫mero de √©pocas
batch_size = 32                               # Tama√±o de lote
steps_per_epoch = int(np.ceil(len(X_entrenamiento) / batch_size))
validation_steps = int(np.ceil(len(X_validacion) / batch_size))
```

**Detalles t√©cnicos:**
- **TensorBoard**: Herramienta de visualizaci√≥n para monitorear entrenamiento en tiempo real
- **Batch size 32**: Equilibrio entre memoria GPU y estabilidad del gradiente
- `steps_per_epoch`: N√∫mero de lotes necesarios para procesar todo el dataset de entrenamiento
- `np.ceil()`: Redondeo hacia arriba para incluir datos residuales

### **SECCI√ìN 11: ENTRENAMIENTO DEL MODELO (L√≠neas 203-217)**

```python
print(f"√âpocas: {epochs}")
print(f"Pasos por √©poca: {steps_per_epoch}")

print("\n=== INICIANDO ENTRENAMIENTO ===")

# Entrenar el modelo
historial = modelo_asl.fit(
    data_gen_entrenamiento,                    # Generador con datos aumentados
    epochs=epochs,
    batch_size=batch_size,
    validation_data=(X_validacion, y_validacion),  # Datos para validaci√≥n
    steps_per_epoch=steps_per_epoch,
    validation_steps=validation_steps,
    callbacks=[tensorboard_callback],          # Logging para TensorBoard
    verbose=1                                  # Mostrar progreso detallado
)
```

**Detalles t√©cnicos:**
- **Generador vs datos est√°ticos**: Permite data augmentation en tiempo real
- **Validation data**: Evaluaci√≥n en cada √©poca sin influir en el entrenamiento
- **Callbacks**: Funciones ejecutadas en puntos espec√≠ficos del entrenamiento
- **Verbose=1**: Muestra barra de progreso y m√©tricas por √©poca

### **SECCI√ìN 12: EVALUACI√ìN Y GUARDADO (L√≠neas 218-240)**

```python
print("\n=== ENTRENAMIENTO COMPLETADO ===")

# Guardar el modelo
nombre_modelo = 'modelo_asl_augmented.h5'
modelo_asl.save(nombre_modelo)
print(f"Modelo guardado como: {nombre_modelo}")

# Mostrar m√©tricas finales
train_accuracy = historial.history['accuracy'][-1]        # √öltima √©poca
val_accuracy = historial.history['val_accuracy'][-1]
train_loss = historial.history['loss'][-1]
val_loss = historial.history['val_loss'][-1]

print(f"\n=== M√âTRICAS FINALES ===")
print(f"Precisi√≥n de entrenamiento: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)")
print(f"Precisi√≥n de validaci√≥n: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)")
print(f"P√©rdida de entrenamiento: {train_loss:.4f}")
print(f"P√©rdida de validaci√≥n: {val_loss:.4f}")
```

**Detalles t√©cnicos:**
- **Formato HDF5**: Est√°ndar para modelos de Keras, incluye arquitectura y pesos
- `historial.history`: Diccionario con m√©tricas de todas las √©pocas
- **√çndice [-1]**: Accede al √∫ltimo elemento (√©poca final)
- **Formateo de precisi√≥n**: Muestra 4 decimales y porcentaje para claridad

### **SECCI√ìN 13: VISUALIZACI√ìN DE RESULTADOS (L√≠neas 241-265)**

```python
# Crear gr√°fica de entrenamiento
plt.figure(figsize=(15, 5))

# Gr√°fica de precisi√≥n
plt.subplot(1, 2, 1)
plt.plot(historial.history['accuracy'], label='Entrenamiento')
plt.plot(historial.history['val_accuracy'], label='Validaci√≥n')
plt.title('Precisi√≥n del Modelo')
plt.xlabel('√âpoca')
plt.ylabel('Precisi√≥n')
plt.legend()
plt.grid(True)

# Gr√°fica de p√©rdida
plt.subplot(1, 2, 2)
plt.plot(historial.history['loss'], label='Entrenamiento')
plt.plot(historial.history['val_loss'], label='Validaci√≥n')
plt.title('P√©rdida del Modelo')
plt.xlabel('√âpoca')
plt.ylabel('P√©rdida')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()
```

**Detalles t√©cnicos:**
- **Subplots lado a lado**: Permite comparaci√≥n visual simult√°nea
- **Curvas de entrenamiento vs validaci√≥n**: Esencial para detectar overfitting
- **Grid**: Facilita lectura de valores espec√≠ficos
- **Interpretaci√≥n**: Convergencia indica buen entrenamiento, divergencia indica overfitting

### **SECCI√ìN 14: EXPORTACI√ìN A TENSORFLOW.JS (L√≠neas 266-285)**

```python
print(f"\n=== EXPORTACI√ìN A TENSORFLOW.JS ===")

# Instalar tensorflowjs si no est√° instalado
try:
    import tensorflowjs as tfjs
    print("TensorFlow.js ya est√° instalado")
except ImportError:
    print("Instalando TensorFlow.js...")
    import subprocess
    subprocess.check_call(['pip', 'install', 'tensorflowjs'])
    import tensorflowjs as tfjs

# Exportar modelo a TensorFlow.js
modelo_js_path = 'modelo_exportado/modelo_asl_js'
os.makedirs(modelo_js_path, exist_ok=True)

# Convertir modelo a formato TensorFlow.js
tfjs.converters.save_keras_model(modelo_asl, modelo_js_path)
print(f"Modelo exportado a TensorFlow.js en: {modelo_js_path}")
```

**Detalles t√©cnicos:**
- **Instalaci√≥n din√°mica**: Instala dependencia solo si es necesaria
- **subprocess.check_call()**: Ejecuta comando pip y verifica √©xito
- **Conversi√≥n autom√°tica**: Convierte arquitectura y pesos a formato web
- **Archivos generados**: model.json (arquitectura) + archivos .bin (pesos)

### **SECCI√ìN 15: INFORMACI√ìN FINAL (L√≠neas 286-297)**

```python
print(f"\n=== INFORMACI√ìN DEL MODELO ENTRENADO ===")
print(f"N√∫mero de clases: {num_clases}")
print(f"Clases del modelo: {metadatos['clases']}")
print(f"\nArchivos generados:")
print(f"- Modelo Keras (.h5): {nombre_modelo}")
print(f"- Modelo TensorFlow.js: {modelo_js_path}/")
print(f"- Logs de TensorBoard: logs/asl_cnn_augmented/")

print(f"\nTipo de salida del modelo:")
print(f"- Array de probabilidades de forma (1, {num_clases})")
print(f"- Cada elemento representa la probabilidad de cada clase")
print(f"- La suma de todas las probabilidades es 1.0")
print(f"- Para obtener la predicci√≥n: np.argmax(modelo.predict(imagen))")

print("\n¬°Modelo listo para usar en aplicaciones web con TensorFlow.js!")
```

**Detalles t√©cnicos:**
- **Documentaci√≥n autom√°tica**: Resume informaci√≥n clave del modelo entrenado
- **Gu√≠a de uso**: Explica c√≥mo interpretar las predicciones
- **Archivos de salida**: Lista completa de artifacts generados
- **Formato de predicci√≥n**: Explica estructura de salida softmax

---

## üéØ CARACTER√çSTICAS T√âCNICAS DESTACADAS

### **Optimizaciones de Memoria**
- Uso de listas de tuplas en lugar de arrays NumPy prematuros
- Conversi√≥n a float32 en lugar de float64 para eficiencia GPU
- Batch processing para evitar cargar todo el dataset en memoria

### **T√©cnicas de Regularizaci√≥n**
- **Dropout**: 50% y 30% en capas densas para prevenir overfitting
- **Data Augmentation**: 8 tipos diferentes de transformaciones
- **Validation Set**: 15% de datos para evaluaci√≥n independiente

### **Robustez y Reproducibilidad**
- Creaci√≥n autom√°tica de directorios
- Validaci√≥n de datos en m√∫ltiples puntos
- Logging completo con TensorBoard
- Manejo de errores en importaciones

### **Escalabilidad**
- Arquitectura modular f√°cil de modificar
- Configuraci√≥n mediante variables al inicio
- Generadores para datasets grandes
- Exportaci√≥n m√∫ltiple (Keras + TensorFlow.js)

---

## üìà M√âTRICAS Y EVALUACI√ìN

### **M√©tricas Monitoreadas**
- **Accuracy**: Porcentaje de predicciones correctas
- **Loss**: Valor de la funci√≥n de p√©rdida (menor es mejor)
- **Validation metrics**: Mismas m√©tricas en datos no entrenados

### **Visualizaciones Generadas**
- Ejemplos del dataset original
- Ejemplos de datos aumentados
- Curvas de entrenamiento (accuracy y loss)
- Comparaci√≥n entrenamiento vs validaci√≥n

### **Archivos de Salida**
- `modelo_asl_augmented.h5`: Modelo completo de Keras
- `modelo_exportado/modelo_asl_js/`: Modelo para web
- `logs/asl_cnn_augmented/`: Logs de TensorBoard

---

## üîß CONFIGURACI√ìN Y PAR√ÅMETROS

### **Hiperpar√°metros Principales**
- **√âpocas**: 100 (ajustable en l√≠nea 185)
- **Batch Size**: 32 (ajustable en l√≠nea 186)
- **Learning Rate**: Por defecto de Adam (~0.001)
- **Tama√±o de imagen**: 100x100 p√≠xeles
- **Split de datos**: 85% entrenamiento, 15% validaci√≥n

### **Par√°metros de Data Augmentation**
- **Rotaci√≥n**: ¬±30 grados
- **Desplazamiento**: ¬±20% horizontal y vertical
- **Zoom**: 70%-140%
- **Volteos**: Horizontal y vertical habilitados

### **Arquitectura CNN**
- **Capas convolucionales**: 3 (32, 64, 128 filtros)
- **Capas densas**: 2 (128 neuronas + output)
- **Dropout**: 50% y 30%
- **Funci√≥n de activaci√≥n**: ReLU (ocultas), Softmax (salida)

---

## üöÄ GU√çA DE EJECUCI√ìN

### **Requisitos Previos**
1. Dataset ASL en `./asl_alphabet_train/`
2. Python 3.7+ con las dependencias instaladas
3. M√≠nimo 8GB RAM (recomendado)
4. GPU opcional pero recomendada

### **Ejecuci√≥n**
```bash
python index.py
```

### **Salidas Esperadas**
- Modelo entrenado guardado como `modelo_asl_augmented.h5`
- Modelo web en `modelo_exportado/modelo_asl_js/`
- Logs de TensorBoard en `logs/asl_cnn_augmented/`
- Gr√°ficas de rendimiento mostradas en pantalla

### **Tiempo de Ejecuci√≥n Estimado**
- **CPU**: 2-4 horas (dependiendo del hardware)
- **GPU**: 30-60 minutos
- **Carga de datos**: 5-10 minutos
- **Exportaci√≥n**: 1-2 minutos

### **Soluci√≥n de Problemas Comunes**
- **Error de memoria**: Reducir batch_size a 16 o 8
- **Convergencia lenta**: Verificar calidad del dataset
- **Error en exportaci√≥n**: Verificar instalaci√≥n de tensorflowjs

---

## üìù NOTAS T√âCNICAS ADICIONALES

### **Decisiones de Dise√±o**
- **Escala de grises**: Reduce complejidad manteniendo informaci√≥n esencial
- **Tama√±o 100x100**: Equilibrio entre detalle y eficiencia computacional
- **Sequential API**: M√°s simple que Functional API para esta arquitectura lineal

### **Mejoras Posibles**
- Implementar data balancing para clases desbalanceadas
- Agregar t√©cnicas de regularizaci√≥n L1/L2
- Implementar learning rate scheduling
- Usar transfer learning con modelos preentrenados
- Implementar cross-validation para evaluaci√≥n m√°s robusta

### **Compatibilidad**
- **TensorFlow**: 2.x (recomendado 2.8+)
- **Python**: 3.7, 3.8, 3.9, 3.10
- **OpenCV**: 4.x
- **Navegadores web**: Chrome, Firefox, Safari, Edge (modernos)

Esta documentaci√≥n proporciona una comprensi√≥n completa del funcionamiento interno del script `index.py`, desde los detalles t√©cnicos de implementaci√≥n hasta las decisiones de dise√±o y optimizaciones aplicadas.
