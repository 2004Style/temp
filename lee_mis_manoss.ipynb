{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l-T47pwYw8qr"
   },
   "outputs": [],
   "source": [
    "# Cargar imágenes y etiquetas desde la estructura de carpetas asl_alphabet\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "ruta_base = './asl_alphabet_train'  # Ajusta si tu ruta es diferente\n",
    "TAMANO_IMG = 100\n",
    "\n",
    "clases = sorted([d for d in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, d))])\n",
    "train = []\n",
    "for idx, clase in enumerate(clases):\n",
    "    ruta_clase = os.path.join(ruta_base, clase)\n",
    "    for archivo in os.listdir(ruta_clase):\n",
    "        if archivo.endswith('.jpg') or archivo.endswith('.png'):\n",
    "            ruta_img = os.path.join(ruta_clase, archivo)\n",
    "            img = cv2.imread(ruta_img)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (TAMANO_IMG, TAMANO_IMG))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                img = img.reshape(TAMANO_IMG, TAMANO_IMG, 1)\n",
    "                train.append((img, idx))  # Tupla (imagen, etiqueta)\n",
    "\n",
    "# NO crear X ni y como arrays aquí para evitar duplicación de datos y consumo de RAM\n",
    "datos = {'train': train}\n",
    "metadatos = {'clases': clases, 'total_imagenes': len(train), 'tamano_img': TAMANO_IMG}\n",
    "\n",
    "print(f'Total de imágenes cargadas: {len(train)}')\n",
    "print(f'Clases encontradas: {clases}')\n",
    "\n",
    "\n",
    "# Mostrar información básica de los datos y metadatos (simulado)\n",
    "print('Metadatos:')\n",
    "print(metadatos)\n",
    "print('Primer ejemplo:')\n",
    "ejemplo_img, ejemplo_et = datos['train'][0]\n",
    "print(f\"Clase: {metadatos['clases'][ejemplo_et]}\")\n",
    "print(f\"Tamaño imagen: {ejemplo_img.shape}\")\n",
    "\n",
    "# Mostrar 5 ejemplos del set usando datos['train'] y metadatos\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    img, etiqueta = datos['train'][i]\n",
    "    img = img.reshape(metadatos['tamano_img'], metadatos['tamano_img'])\n",
    "    axs[i].imshow(img, cmap='gray')\n",
    "    axs[i].set_title(metadatos['clases'][etiqueta])\n",
    "    axs[i].axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Mostrar un ejemplo de cada clase usando datos['train'] y metadatos\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, len(metadatos['clases']), figsize=(20, 3))\n",
    "for idx, clase in enumerate(metadatos['clases']):\n",
    "    for img, et in datos['train']:\n",
    "        if et == idx:\n",
    "            img = img.reshape(metadatos['tamano_img'], metadatos['tamano_img'])\n",
    "            axs[idx].imshow(img, cmap='gray')\n",
    "            axs[idx].set_title(clase)\n",
    "            axs[idx].axis('off')\n",
    "            break\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Manipular y visualizar el set\n",
    "#Lo pasamos a TAMANO_IMG (100x100) y a blanco y negro (solo para visualizar)\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "TAMANO_IMG=100\n",
    "\n",
    "for i, (imagen, etiqueta) in enumerate(datos['train'][:25]):\n",
    "  imagen = imagen.reshape(TAMANO_IMG, TAMANO_IMG)\n",
    "  plt.subplot(5, 5, i+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.imshow(imagen, cmap='gray')\n",
    "  plt.title(metadatos['clases'][etiqueta])\n",
    "plt.show()\n",
    "\n",
    "#Variable que contendra todos los pares de los datos (imagen y etiqueta) ya modificados (blanco y negro, 100x100)\n",
    "datos_entrenamiento = []\n",
    "\n",
    "for i, (imagen, etiqueta) in enumerate(datos['train']): #Todos los datos\n",
    "  imagen = cv2.resize(imagen, (TAMANO_IMG, TAMANO_IMG))\n",
    "  #imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
    "  imagen = imagen.reshape(TAMANO_IMG, TAMANO_IMG, 1) #Cambiar tamano a 100,100,1\n",
    "  datos_entrenamiento.append([imagen, etiqueta])\n",
    "\n",
    "#Ver los datos del primer indice\n",
    "datos_entrenamiento[0]\n",
    "\n",
    "#Ver cuantos datos tengo en la variable\n",
    "len(datos_entrenamiento)\n",
    "\n",
    "# Preparar listas X (imagenes) y y (etiquetas) solo para normalización y entrenamiento\n",
    "X = [imagen for imagen, etiqueta in datos['train']]\n",
    "y = [etiqueta for imagen, etiqueta in datos['train']]\n",
    "\n",
    "X\n",
    "\n",
    "# Normalizar los datos de las X (imagenes) en lotes para evitar problemas de memoria.\n",
    "import numpy as np\n",
    "\n",
    "def normalizar_en_lotes(X_lista, tamano_lote=100):\n",
    "    X_normalizado = []\n",
    "    for i in range(0, len(X_lista), tamano_lote):\n",
    "        lote = np.array(X_lista[i:i+tamano_lote]).astype(float) / 255\n",
    "        X_normalizado.append(lote)\n",
    "    return np.concatenate(X_normalizado, axis=0)\n",
    "\n",
    "# Asegurando que X no sea un array antes de la normalización\n",
    "X = normalizar_en_lotes(X, tamano_lote=100)\n",
    "\n",
    "# Mostrar la variable y (etiquetas) solo si está definida y es un array\n",
    "print(y)\n",
    "\n",
    "# Convertir etiquetas en arreglo simple solo después de la normalización\n",
    "y = np.array(y)\n",
    "\n",
    "X.shape\n",
    "\n",
    "#Crear los modelos iniciales para clasificación multiclase (ASL Alphabet, 29 clases)\n",
    "# Usan softmax como salida y sparse_categorical_crossentropy como función de pérdida.\n",
    "num_clases = len(metadatos['clases'])\n",
    "\n",
    "modeloCNN = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(100, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_clases, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compilar modelos para clasificación multiclase (ASL Alphabet, 29 clases)\n",
    "\n",
    "modeloCNN.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboardCNN = TensorBoard(log_dir='logs/cnn')\n",
    "modeloCNN.fit(X, y, batch_size=32,\n",
    "                validation_split=0.15,\n",
    "                epochs=100,\n",
    "                callbacks=[tensorboardCNN])\n",
    "\n",
    "#ver las imagenes de la variable X sin modificaciones por aumento de datos\n",
    "plt.figure(figsize=(20, 8))\n",
    "for i in range(10):\n",
    "  plt.subplot(2, 5, i+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.imshow(X[i].reshape(100, 100), cmap=\"gray\")\n",
    "\n",
    "#Realizar el aumento de datos con varias transformaciones. Al final, graficar 10 como ejemplo\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=15,\n",
    "    zoom_range=[0.7, 1.4],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "datagen.fit(X)\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "for imagen, etiqueta in datagen.flow(X, y, batch_size=10, shuffle=False):\n",
    "  for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(imagen[i].reshape(100, 100), cmap=\"gray\")\n",
    "  break\n",
    "\n",
    "modeloCNN_AD = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "  #tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(100, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "modeloCNN_AD.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "#Separar los datos de entrenamiento y los datos de pruebas en variables diferentes\n",
    "\n",
    "len(X) * .85 #19700\n",
    "len(X) - 19700 #3562\n",
    "\n",
    "X_entrenamiento = X[:19700]\n",
    "X_validacion = X[19700:]\n",
    "\n",
    "y_entrenamiento = y[:19700]\n",
    "y_validacion = y[19700:]\n",
    "\n",
    "#Usar la funcion flow del generador para crear un iterador que podamos enviar como entrenamiento a la funcion FIT del modelo\n",
    "data_gen_entrenamiento = datagen.flow(X_entrenamiento, y_entrenamiento, batch_size=32)\n",
    "\n",
    "tensorboardCNN_AD = TensorBoard(log_dir='logs-new/cnn_AD')\n",
    "\n",
    "modeloCNN_AD.fit(\n",
    "    data_gen_entrenamiento,\n",
    "    epochs=150, batch_size=32,\n",
    "    validation_data=(X_validacion, y_validacion),\n",
    "    steps_per_epoch=int(np.ceil(len(X_entrenamiento) / float(32))),\n",
    "    validation_steps=int(np.ceil(len(X_validacion) / float(32))),\n",
    "    callbacks=[tensorboardCNN_AD]\n",
    ")\n",
    "\n",
    "modeloCNN_AD.save('modelo-cnn-ad.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vmRBuHwG5BOY"
   },
   "outputs": [],
   "source": [
    "#Cargar la extension de tensorboard de colab\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_xqqhin5Db_"
   },
   "outputs": [],
   "source": [
    "#Ejecutar tensorboard e indicarle que lea la carpeta \"logs\"\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bcUG8NoKA1ee"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8dSa1UzA4eW"
   },
   "outputs": [],
   "source": [
    "!mkdir carpeta_salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEE6r07ZA6Mz"
   },
   "outputs": [],
   "source": [
    "!tensorflowjs_converter --input_format keras perros-gatos-cnn-ad.h5 carpeta_salida"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
